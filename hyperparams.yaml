#=====================================================================
#   Project:      SAn Energy-Efficient Spiking Neural Network for Finger Velocity Decoding for Implantable Brain-Machine Interface
#   File:         hyperparams.py
#   Description:  Yaml file for setting the hyperparameters
#
#   Date:        10. April 2022
#
#=====================================================================
#
#   Copyright (C) 2022 ETH Zurich.
#
#   Author: Lars Widmer
#
#   SPDX-License-Identifier: Apache-2.0
#
#   Licensed under the Apache License, Version 2.0 (the License); you may
#   not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#   www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an AS IS BASIS, WITHOUT
#   WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#
#   See the License for the specific language governing permissions and
#   limitations under the License.
#
#   Please see the File "LICENCE.md" for the full licensing information.
#
#=====================================================================


---
#Training
 batch_size: 128 #how many samples per batch
 epochs: 43 #how many epochs to train for (maximum epochs)
 early_stopping_patience: -1 #How many epochs to continue training with no improvement. -1 for infinite patience.
 loss: L2 # "L1", "L2" or "corr" for training using the corresponding loss function
 learning_rate: 2e-3 #learning rate
 dropout: 0.3 #dropout probability
 weight_decay: 0.005 #L2 weight decay strength
 steps: 10 #how many steps to unfold the SNN for in training
 warmup_steps: 2 #how many steps results to discard in the loss calculation
 
#Neuron
 Vth: 0.4 #Threshold value for the LIF neurons

 tau: 0.6 #Initial value of the decay parameter in the LIF neurons
 tau_init_range: 0.1 #width of the distribution of the decay parameter initialisaion when it is trainable
 tau_trainable: True #Trainable or non-trainable decay
 constrain_method: 'forward' #When to constrain the decay parameters range. 
 #options are 'none' (no constraining), 'forward' (constraining only in the forward pass), 
 #'always' (always strictly constraining the value) and 'eval'(only constrain the value in the evaluation)

 reset_by_subtraction: True #Reset mechanism of the LIF neuron. True -> reset by subtraction, False -> reset to zero
 surrogate_gradient: 'square' #surrogate gradient function. currently only 'square' is implemented

 init_u: 'zero' #What to initialize the membrane potential to when starting the network. 
 #options are 'zero' (all zero), 'random' (flat distribution between 0 and Vth) and 'Vth' (all just below Vth)


#Dataset
 output_type: 'vel' #what to predict, options are 'pos', 'vel', 'acc'.
 
#Network
 batchnorm: 'tdBN' #What Batch normalisation to use. Currently only 'tdBN' (threshold dependandt batch normalisation) and 'none' implemented.
 neuron_count: 256 #count of neurons per fully connected layer
 use_bias: True #Are the Neurons are allowed to have a bias or not

#Reporting
 loss_steps: 50 #How often to report the loss during training in the report file (after every xth Batch)
 output_report: Report.txt #Where to save the results and training info to 
 output_plots: plots/ #which folder to save the plots to 

#General
 seed: 123 #Seed for initialisation. Use 'random' for a non-deterministic seed
 device: cuda:0 #Which cuda device to train on
 trials: 10 #How many initialisations to evaluate the network for
 5-fold: False #Use 5-fold validation or not: 
 #True -> Split the training dataset into 5 folds, then use 4 for training and 1 for (holdout) evaluation. Repeat 5 times such that evey fold is the evaluation set once. 
 #False -> Use the entire training dataset for training and test the network on the test set. DO NOT USE FOR HYPERPARRAMETER TUNING!
 early_stopping: False #Use early stopping or not
 dataset_file: /scratch/msc21h12/datasets/dataset_processed_2020.mat #File where the preprocessed dataset is found

#save and load model
 save_model: False #If the model should be saved
 save_model_dir: model/ #which folder to save the model to 
 load_model: False  #If a model should be loaded and evaluated (whithout further training)
 load_model_dir: model/model_trial_0_fold_0_epoch_42_id_993906.pt #Which file to load the model from